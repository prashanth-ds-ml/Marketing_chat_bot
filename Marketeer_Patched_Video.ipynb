{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§  Marketeer â€” Conversational Marketing Bot (Patched)\n",
        "\n",
        "**This version fixes video scripting returning empty content** by:\n",
        "- Using Gemma-friendly prompting (no `system` role for JSON blocks)\n",
        "- Strong JSON extraction + graceful fallback per beat\n",
        "- REPL `/video` is fully wired to `make_video()`\n",
        "- Includes a quick selfâ€‘test cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â–¶ Python: 3.10.11\n",
            "â–¶ Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
            "\n",
            "â–¶ nvidia-smi:\n",
            "Thu Nov 13 00:51:03 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.35.03              Driver Version: 561.09         CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3060 ...    On  |   00000000:01:00.0  On |                  N/A |\n",
            "| N/A   57C    P8             13W /   85W |    4961MiB /   6144MiB |     13%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      6286      C   /python3.10                                 N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys, subprocess, platform\n",
        "print(f'â–¶ Python: {sys.version.split()[0]}')\n",
        "print(f'â–¶ Platform: {platform.platform()}')\n",
        "print('\\nâ–¶ nvidia-smi:')\n",
        "try:\n",
        "    print(subprocess.check_output(['nvidia-smi'], text=True))\n",
        "except Exception:\n",
        "    print('(no GPU visible)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install base libs\n",
        "(If already installed, this is a no-op.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip -q install --upgrade pip\n",
        "# %pip -q install transformers accelerate sentence-transformers faiss-cpu pypdf textstat regex tiktoken rich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, transformers, textwrap, re, json\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from typing import List, Dict, Any\n",
        "from collections import deque\n",
        "print({'torch': torch.__version__, 'transformers': transformers.__version__})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "import re\n",
        "\n",
        "PLATFORM_RULES: Dict[str, Dict[str, int]] = {\n",
        "    'Instagram':   {'cap': 2200, 'hashtags_max': 5, 'emoji_max': 5},\n",
        "    'Facebook':    {'cap': 125,  'hashtags_max': 0, 'emoji_max': 1},\n",
        "    'LinkedIn':    {'cap': 3000, 'hashtags_max': 3, 'emoji_max': 2},\n",
        "    'Google Ads':  {'cap': 90,   'hashtags_max': 0, 'emoji_max': 0},\n",
        "    'Twitter/X':   {'cap': 280,  'hashtags_max': 2, 'emoji_max': 2},\n",
        "}\n",
        "\n",
        "BANNED_MAP = {\n",
        "    r'\\bguarantee(d|s)?\\b': 'aim to',\n",
        "    r'\\bno[-\\s]?risk\\b': 'low risk',\n",
        "    r'\\bno[-\\s]?questions[-\\s]?asked\\b': 'hassle-free',\n",
        "    r'\\b#?1\\b': 'top-rated',\n",
        "    r'\\bbest\\b': 'trusted',\n",
        "    r'\\bfastest\\b': 'fast',\n",
        "}\n",
        "EMOJI_RX   = re.compile(r'[\\U0001F300-\\U0001FAFF\\U00002700-\\U000027BF]')\n",
        "HASHTAG_RX = re.compile(r'(#\\w+)')\n",
        "SPACE_RX   = re.compile(r'\\s+')\n",
        "\n",
        "def _replace_banned(text: str, audit: List[str]) -> str:\n",
        "    new = text\n",
        "    for pat, repl in BANNED_MAP.items():\n",
        "        if re.search(pat, new, flags=re.I):\n",
        "            new = re.sub(pat, repl, new, flags=re.I)\n",
        "            audit.append(f\"Replaced banned phrasing '{pat}' -> '{repl}'.\")\n",
        "    return new\n",
        "\n",
        "def _limit_hashtags(s: str, max_tags: int, audit: List[str]) -> str:\n",
        "    tags = HASHTAG_RX.findall(s)\n",
        "    if max_tags == 0 and tags:\n",
        "        s2 = HASHTAG_RX.sub('', s)\n",
        "        s2 = SPACE_RX.sub(' ', s2).strip()\n",
        "        audit.append('Removed all hashtags per platform rules.')\n",
        "        return s2\n",
        "    if len(tags) <= max_tags:\n",
        "        return s\n",
        "    count = 0\n",
        "    toks = s.split()\n",
        "    for i, tok in enumerate(toks):\n",
        "        if tok.startswith('#'):\n",
        "            count += 1\n",
        "            if count > max_tags:\n",
        "                toks[i] = ''\n",
        "    s2 = ' '.join(t for t in toks if t)\n",
        "    audit.append(f'Trimmed hashtags to <= {max_tags}.')\n",
        "    return s2\n",
        "\n",
        "def _limit_emojis(s: str, max_emojis: int, audit: List[str]) -> str:\n",
        "    if max_emojis < 0:\n",
        "        return s\n",
        "    emojis = EMOJI_RX.findall(s)\n",
        "    if len(emojis) <= max_emojis:\n",
        "        return s\n",
        "    kept = 0; out = []\n",
        "    for ch in s:\n",
        "        if EMOJI_RX.match(ch):\n",
        "            if kept < max_emojis:\n",
        "                out.append(ch); kept += 1\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    audit.append(f'Trimmed emojis to <= {max_emojis}.')\n",
        "    return ''.join(out)\n",
        "\n",
        "def _ensure_keywords(s: str, keywords: List[str], cap: int, audit: List[str]) -> str:\n",
        "    text = s\n",
        "    for kw in (keywords or []):\n",
        "        if kw.strip() and re.search(re.escape(kw), text, flags=re.I) is None:\n",
        "            cand = (text + ' ' + kw).strip()\n",
        "            if len(cand) <= cap:\n",
        "                text = cand\n",
        "            else:\n",
        "                parts = text.split()\n",
        "                if parts:\n",
        "                    parts[-1] = kw\n",
        "                    text = ' '.join(parts)\n",
        "            audit.append(f'Inserted missing keyword: {kw}')\n",
        "    return text\n",
        "\n",
        "def _pick_cta(cta_strength: str) -> str:\n",
        "    bank = {\n",
        "        'soft':   ['Learn more','See how it works','Try it free'],\n",
        "        'medium': ['Get started today','Start now'],\n",
        "        'hard':   ['Start your free trial now','Buy now','Sign up now'],\n",
        "    }.get(cta_strength, ['Learn more'])\n",
        "    return bank[0]\n",
        "\n",
        "def _ensure_cta(text: str, cta_strength: str, audit: List[str]) -> str:\n",
        "    if re.search(r'\\b(learn more|start|try|buy|sign up|get started|discover|explore)\\b', text, flags=re.I):\n",
        "        return text\n",
        "    cta = _pick_cta(cta_strength)\n",
        "    audit.append(f\"Added CTA: '{cta}'.\")\n",
        "    return (text + (' ' if not text.endswith(('.', '!', '?')) else ' ') + cta).strip()\n",
        "\n",
        "def _smart_trim(text: str, cap: int, preserve_tail: str = '') -> str:\n",
        "    if len(text) <= cap:\n",
        "        return text\n",
        "    reserve = len(preserve_tail) + (1 if preserve_tail and not text.endswith(' ') else 0)\n",
        "    hard = max(0, cap - reserve)\n",
        "    trimmed = text[:hard].rstrip()\n",
        "    if preserve_tail:\n",
        "        if not trimmed.endswith(('.', '!', '?')):\n",
        "            trimmed = trimmed.rstrip(',;:-')\n",
        "        trimmed = (trimmed + ' ' + preserve_tail).strip()\n",
        "    return trimmed[:cap]\n",
        "\n",
        "def apply_validators(text: str, platform: str, cap: int, cta_strength: str, keywords: List[str]):\n",
        "    audit: List[str] = []\n",
        "    s = text.strip()\n",
        "    s = _replace_banned(s, audit)\n",
        "    s = _ensure_cta(s, cta_strength, audit)\n",
        "    s = _ensure_keywords(s, keywords, 10**9, audit)\n",
        "    tail_cta = ''\n",
        "    m = re.search(r'(learn more|start your free trial(?: now)?|start now|try it free|get started(?: today)?|buy now|sign up(?: now)?)$', s, flags=re.I)\n",
        "    if m:\n",
        "        tail_cta = m.group(0)\n",
        "    s = _smart_trim(s, cap, preserve_tail=tail_cta)\n",
        "    s = _ensure_keywords(s, keywords, cap, audit)\n",
        "    rule = PLATFORM_RULES.get(platform, PLATFORM_RULES['Instagram'])\n",
        "    s = _limit_hashtags(s, rule['hashtags_max'], audit)\n",
        "    s = _limit_emojis(s, rule['emoji_max'], audit)\n",
        "    if len(s) > cap:\n",
        "        s = s[:cap].rstrip()\n",
        "        audit.append(f'Force-clipped to {cap} chars.')\n",
        "    return s, audit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ShortWindowMemory:\n",
        "    def __init__(self, k: int = 3):\n",
        "        self.window = deque(maxlen=k)\n",
        "    def add(self, user: str, assistant: str):\n",
        "        self.window.append({'user': user, 'assistant': assistant})\n",
        "    def text(self) -> str:\n",
        "        if not self.window:\n",
        "            return ''\n",
        "        lines = []\n",
        "        for t in self.window:\n",
        "            lines.append(f\"Human: {t['user']}\")\n",
        "            lines.append(f\"AI: {t['assistant']}\")\n",
        "        return '\\n'.join(lines)\n",
        "    def reset(self):\n",
        "        self.window.clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SESSION_PROFILE: Dict[str, Any] = {\n",
        "    'brand': '', 'product': '', 'audience': '', 'voice': '', 'facts': {}\n",
        "}\n",
        "def remember(k: str, v: str):\n",
        "    if k in ('brand','product','audience','voice'):\n",
        "        SESSION_PROFILE[k] = v\n",
        "    else:\n",
        "        SESSION_PROFILE['facts'][k] = v\n",
        "    return SESSION_PROFILE\n",
        "def forget(k: str):\n",
        "    if k in ('brand','product','audience','voice'):\n",
        "        SESSION_PROFILE[k] = ''\n",
        "    else:\n",
        "        SESSION_PROFILE['facts'].pop(k, None)\n",
        "    return SESSION_PROFILE\n",
        "def facts_dump() -> str:\n",
        "    f = [f\"- brand: {SESSION_PROFILE.get('brand','')}\",\n",
        "         f\"- product: {SESSION_PROFILE.get('product','')}\",\n",
        "         f\"- audience: {SESSION_PROFILE.get('audience','')}\",\n",
        "         f\"- voice: {SESSION_PROFILE.get('voice','')}\"]\n",
        "    if SESSION_PROFILE['facts']:\n",
        "        f.append('- facts:')\n",
        "        for k,v in SESSION_PROFILE['facts'].items():\n",
        "            f.append(f\"  â€¢ {k}: {v}\")\n",
        "    return '\\n'.join(f)\n",
        "BASE_GUIDANCE = (\n",
        "    'You are Marketeer, a concise, benefit-first marketing copywriter. '\n",
        "    'Respect the platform\\'s character cap, include required keywords, and end with a clear but compliant CTA. '\n",
        "    \"Avoid absolute claims like 'guaranteed', '#1', or 'best'. Prefer modest, evidence-backed phrasing.\"\n",
        ")\n",
        "def _profile_block() -> str:\n",
        "    lines = []\n",
        "    if any(SESSION_PROFILE.values()):\n",
        "        lines.append('Session profile:')\n",
        "        if SESSION_PROFILE.get('brand'):   lines.append(f\"- Brand: {SESSION_PROFILE['brand']}\")\n",
        "        if SESSION_PROFILE.get('product'): lines.append(f\"- Product: {SESSION_PROFILE['product']}\")\n",
        "        if SESSION_PROFILE.get('audience'):lines.append(f\"- Audience: {SESSION_PROFILE['audience']}\")\n",
        "        if SESSION_PROFILE.get('voice'):   lines.append(f\"- Voice: {SESSION_PROFILE['voice']}\")\n",
        "        if SESSION_PROFILE['facts']:\n",
        "            lines.append('- Key facts:')\n",
        "            for k,v in SESSION_PROFILE['facts'].items():\n",
        "                lines.append(f\"  â€¢ {k}: {v}\")\n",
        "    return '\\n'.join(lines) if lines else '[no session profile]'\n",
        "import textwrap\n",
        "def build_prompt(user_input: str, platform: str, tone: str, cta_strength: str, cap: int,\n",
        "                 keywords: List[str], history_text: str = '') -> str:\n",
        "    kw = ', '.join(keywords) if keywords else '(none)'\n",
        "    profile = _profile_block()\n",
        "    return textwrap.dedent(f\"\"\"\n",
        "    {BASE_GUIDANCE}\n",
        "\n",
        "    Context (recent conversation, if any):\n",
        "    {history_text if history_text else '[no prior turns in memory]'}\n",
        "\n",
        "    {profile}\n",
        "\n",
        "    Task:\n",
        "    - Platform: {platform}\n",
        "    - Tone: {tone}\n",
        "    - CTA strength: {cta_strength}\n",
        "    - Character cap: {cap}\n",
        "    - Required keywords: {kw}\n",
        "\n",
        "    User request:\n",
        "    {user_input}\n",
        "\n",
        "    Instructions:\n",
        "    - Be benefit-first and platform-appropriate.\n",
        "    - Keep within the character cap (hard limit {cap} chars).\n",
        "    - Include all required keywords (if any).\n",
        "    - Close with a clear CTA matching CTA strength.\n",
        "    - Avoid banned claims ('guaranteed', '#1', 'best').\n",
        "\n",
        "    Return only the marketing copy (no preamble).\n",
        "    \"\"\").strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "MODEL_ID = 'google/gemma-2-2b-it'\n",
        "DTYPE = 'bfloat16'\n",
        "try:\n",
        "    token = getpass.getpass('Enter HF token (press Enter to skip): ')\n",
        "    HF_TOKEN = token.strip() or None\n",
        "except Exception:\n",
        "    HF_TOKEN = None\n",
        "torch_dtype = {'bfloat16': torch.bfloat16, 'float16': torch.float16}.get(DTYPE, torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, dtype=torch_dtype, device_map='auto', token=HF_TOKEN)\n",
        "print({'model': MODEL_ID, 'dtype': str(torch_dtype).replace('torch.', '')})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory = ShortWindowMemory(k=3)\n",
        "DEFAULTS = {'platform': 'Instagram', 'tone': 'friendly, energetic', 'cta': 'soft'}\n",
        "def _generate(prompt_text: str, max_new_tokens=180, temperature=0.7, top_p=0.9, repetition_penalty=1.1):\n",
        "    messages = [{'role': 'user', 'content': prompt_text}]\n",
        "    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "    gen_ids = out[0][input_ids.shape[-1]:]\n",
        "    return tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "def send(user: str, platform: str=None, tone: str=None, cta_strength: str=None, cap: int=None, keywords: List[str]=None,\n",
        "         max_new_tokens=180, temperature=0.7, top_p=0.9, repetition_penalty=1.1):\n",
        "    platform = platform or DEFAULTS['platform']\n",
        "    tone = tone or DEFAULTS['tone']\n",
        "    cta_strength = cta_strength or DEFAULTS['cta']\n",
        "    cap = cap or PLATFORM_RULES.get(platform, PLATFORM_RULES['Instagram'])['cap']\n",
        "    keywords = keywords or []\n",
        "    prompt_text = build_prompt(user, platform, tone, cta_strength, cap, keywords, memory.text())\n",
        "    raw = _generate(prompt_text, max_new_tokens, temperature, top_p, repetition_penalty)\n",
        "    final, audit = apply_validators(raw, platform, cap, cta_strength, keywords)\n",
        "    memory.add(user, final)\n",
        "    return {'raw': raw, 'final': final, 'audit': audit, 'cap': cap}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VIDEO_BLUEPRINTS = {\n",
        "    'short_ad': ['Hook (2-3s)','Problem (3-5s)','Product intro (4-6s)','Key benefit (4-6s)','CTA (2-3s)'],\n",
        "    'ugc_review': ['Relatable hook','Pain point','Discovery','Feature demo','Social proof','CTA'],\n",
        "    'how_to': ['Teaser result','Step 1','Step 2','Step 3','Recap + CTA'],\n",
        "}\n",
        "def plan_video(blueprint: str='short_ad', duration_sec: int=20, product_brief: str='') -> Dict[str, Any]:\n",
        "    if blueprint not in VIDEO_BLUEPRINTS:\n",
        "        raise ValueError(f\"Unknown blueprint '{blueprint}'. Options: {list(VIDEO_BLUEPRINTS.keys())}\")\n",
        "    beats = VIDEO_BLUEPRINTS[blueprint]\n",
        "    per_beat = max(2, duration_sec // max(1, len(beats)))\n",
        "    plan = []\n",
        "    for i, beat in enumerate(beats, 1):\n",
        "        plan.append({\n",
        "            'order': i,\n",
        "            'beat': beat,\n",
        "            'time_window': f\"{(i-1)*per_beat:02d}-{min(i*per_beat, duration_sec):02d}s\",\n",
        "        })\n",
        "    return {\n",
        "        'blueprint': blueprint,\n",
        "        'duration_sec': duration_sec,\n",
        "        'beats': plan,\n",
        "        'product_brief': product_brief or '(use chat context)',\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json as _json, re as _re\n",
        "\n",
        "def _session_context_text():\n",
        "    history_text = memory.text()\n",
        "    lines = []\n",
        "    lines.append('=== SESSION PROFILE ===')\n",
        "    if SESSION_PROFILE.get('brand'):   lines.append(f\"Brand: {SESSION_PROFILE['brand']}\")\n",
        "    if SESSION_PROFILE.get('product'): lines.append(f\"Product: {SESSION_PROFILE['product']}\")\n",
        "    if SESSION_PROFILE.get('audience'):lines.append(f\"Audience: {SESSION_PROFILE['audience']}\")\n",
        "    if SESSION_PROFILE.get('voice'):   lines.append(f\"Preferred Voice: {SESSION_PROFILE['voice']}\")\n",
        "    if SESSION_PROFILE.get('facts'):\n",
        "        lines.append('Facts:')\n",
        "        for k,v in SESSION_PROFILE['facts'].items():\n",
        "            lines.append(f\"- {k}: {v}\")\n",
        "    lines.append('\\n=== RECENT CONVERSATION ===')\n",
        "    lines.append(history_text if history_text else '[none]')\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "def _decode_tail(out_ids, start_idx):\n",
        "    return tokenizer.decode(out_ids[0][start_idx:], skip_special_tokens=True).strip()\n",
        "\n",
        "def _just_user_prompt(prompt_text: str, max_new_tokens=320):\n",
        "    messages = [{'role':'user','content': prompt_text}]\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=True, add_generation_prompt=True, return_tensors='pt'\n",
        "    ).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "    return _decode_tail(out, input_ids.shape[-1])\n",
        "\n",
        "def _extract_json(gen_text: str):\n",
        "    try:\n",
        "        return _json.loads(gen_text)\n",
        "    except Exception:\n",
        "        pass\n",
        "    m = _re.search(r'\\{.*\\}', gen_text, flags=_re.S)\n",
        "    if m:\n",
        "        try:\n",
        "            return _json.loads(m.group(0))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "def _fallback_block(beat_title: str):\n",
        "    short = beat_title.split('(')[0].strip()\n",
        "    return {\n",
        "        'voiceover': f\"{short}: naturally delicious, try it today.\",\n",
        "        'on_screen': (short[:32] or 'Fresh & Natural'),\n",
        "        'shots': ['Close-up product', 'Serving scoop', 'Happy bite'],\n",
        "        'broll': ['Farm/ingredient cutaways', 'Pouring/serving'],\n",
        "        'captions': ['Naturally made ice cream', 'From local farms'],\n",
        "    }\n",
        "\n",
        "def script_video_from_plan(plan: dict, style: str = 'friendly, energetic', platform: str = 'Instagram', debug_first=False):\n",
        "    context = _session_context_text()\n",
        "    blueprint = plan.get('blueprint', '?')\n",
        "    duration  = plan.get('duration_sec', 20)\n",
        "    beats     = plan.get('beats', [])\n",
        "    scripted_beats = []\n",
        "\n",
        "    for idx, b in enumerate(beats):\n",
        "        brief = (\n",
        "            context + '\\n\\n'\n",
        "            '=== VIDEO BLUEPRINT ===\\n'\n",
        "            f'Type: {blueprint} | Duration: {duration}s\\n'\n",
        "            f\"Current beat: {b['order']} â€” {b['beat']} ({b['time_window']})\\n\\n\"\n",
        "            'Write concise items with the following constraints:\\n'\n",
        "            '- voiceover: <= 18 words, benefits-first, natural.\\n'\n",
        "            '- on_screen: <= 36 characters, punchy overlay text.\\n'\n",
        "            '- shots: 3 ideas, short imperatives (e.g., \"Close-up pour\").\\n'\n",
        "            '- broll: 2 ideas, short.\\n'\n",
        "            '- captions: 1â€“2 lines, each <= 40 characters.\\n\\n'\n",
        "            f'Platform: {platform}\\n'\n",
        "            f'Style/Tone: {style}\\n\\n'\n",
        "            'Return ONLY valid JSON with keys:\\n'\n",
        "            '{\\n  \"voiceover\": \"string\",\\n  \"on_screen\": \"string\",\\n  \"shots\": [\"...\", \"...\", \"...\"],\\n  \"broll\": [\"...\", \"...\"],\\n  \"captions\": [\"...\", \"...\"]\\n}'\n",
        "        )\n",
        "        gen_text = _just_user_prompt(brief, max_new_tokens=320)\n",
        "        if debug_first and idx == 0:\n",
        "            print('RAW (beat 1):\\n', gen_text)\n",
        "        data = _extract_json(gen_text)\n",
        "        if not data:\n",
        "            data = _fallback_block(b.get('beat','Beat'))\n",
        "\n",
        "        scripted_beats.append({\n",
        "            'order': b.get('order'),\n",
        "            'time_window': b.get('time_window'),\n",
        "            'beat': b.get('beat'),\n",
        "            'voiceover': data.get('voiceover','') or _fallback_block(b.get('beat',''))['voiceover'],\n",
        "            'on_screen': data.get('on_screen','') or _fallback_block(b.get('beat',''))['on_screen'],\n",
        "            'shots': (data.get('shots') or _fallback_block(b.get('beat',''))['shots'])[:3],\n",
        "            'broll': (data.get('broll') or _fallback_block(b.get('beat',''))['broll'])[:2],\n",
        "            'captions': (data.get('captions') or _fallback_block(b.get('beat',''))['captions'])[:2],\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'blueprint': blueprint,\n",
        "        'duration_sec': duration,\n",
        "        'style': style,\n",
        "        'platform': platform,\n",
        "        'product_brief': plan.get('product_brief',''),\n",
        "        'script': scripted_beats\n",
        "    }\n",
        "\n",
        "def make_video(plan_or_blueprint='short_ad', duration=20, product_brief='', style='friendly, energetic', platform='Instagram', debug_first=False):\n",
        "    if isinstance(plan_or_blueprint, dict):\n",
        "        plan = plan_or_blueprint\n",
        "    else:\n",
        "        plan = plan_video(plan_or_blueprint, duration, product_brief)\n",
        "    return script_video_from_plan(plan, style=style, platform=platform, debug_first=debug_first)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "from rich.markdown import Markdown\n",
        "import re, json as _j\n",
        "\n",
        "console = Console()\n",
        "def _print_header():\n",
        "    t = Table(title='Marketeer â€” REPL (Patched)', show_lines=False)\n",
        "    t.add_column('Setting', style='cyan', no_wrap=True)\n",
        "    t.add_column('Value', style='white')\n",
        "    t.add_row('Model', MODEL_ID)\n",
        "    t.add_row('Platform', 'Instagram')\n",
        "    t.add_row('Tone', 'friendly, energetic')\n",
        "    t.add_row('CTA', 'soft')\n",
        "    console.print(t)\n",
        "    console.print(Markdown(\n",
        "        '**Commands**\\n'\n",
        "        '- `/remember key=value`, `/forget key`, `/facts`\\n'\n",
        "        '- `/video blueprint=short_ad duration=20 style=warm platform=Instagram`\\n'\n",
        "        '- Type any prompt to generate copy.'\n",
        "    ))\n",
        "\n",
        "def _parse_kv(line: str):\n",
        "    parts = re.findall(r'(\\w+)=(\".*?\"|\\'.*?\\'|\\S+)', line)\n",
        "    out = {}\n",
        "    for k, v in parts:\n",
        "        v = v.strip().strip('\"').strip(\"'\")\n",
        "        out[k] = v\n",
        "    return out\n",
        "\n",
        "def repl():\n",
        "    _print_header()\n",
        "    while True:\n",
        "        try:\n",
        "            line = console.input('[bold magenta]You[/bold magenta]: ').strip()\n",
        "        except (KeyboardInterrupt, EOFError):\n",
        "            console.print('\\n[yellow]Bye.[/yellow]'); break\n",
        "        if not line:\n",
        "            continue\n",
        "        low = line.lower()\n",
        "        if low in ('/exit','exit','quit','/quit'):\n",
        "            console.print('[yellow]Bye.[/yellow]'); break\n",
        "        if low.startswith('/facts'):\n",
        "            console.print(Panel(facts_dump() or '(no facts)', title='Session Facts')); continue\n",
        "        if low.startswith('/forget'):\n",
        "            kv = _parse_kv(line)\n",
        "            for k in kv.keys(): forget(k)\n",
        "            console.print(Panel('Updated facts.', title='OK')); continue\n",
        "        if low.startswith('/remember'):\n",
        "            kv = _parse_kv(line)\n",
        "            if not kv and '=' in line:\n",
        "                raw = line.split(None, 1)[1]\n",
        "                k,v = raw.split('=',1)\n",
        "                remember(k.strip(), v.strip())\n",
        "            else:\n",
        "                for k,v in kv.items(): remember(k, v)\n",
        "            console.print(Panel('Saved.', title='OK')); continue\n",
        "        if low.startswith('/video'):\n",
        "            kv = _parse_kv(line)\n",
        "            blueprint = kv.get('blueprint','short_ad')\n",
        "            duration  = int(kv.get('duration','20'))\n",
        "            style     = kv.get('style','friendly, energetic')\n",
        "            platformV = kv.get('platform','Instagram')\n",
        "            brief     = SESSION_PROFILE.get('product','') or SESSION_PROFILE.get('brand','') or 'marketing video'\n",
        "            plan = plan_video(blueprint, duration, brief)\n",
        "            script = make_video(plan, style=style, platform=platformV, debug_first=True)\n",
        "            console.print(Panel(_j.dumps(script, indent=2), title='Video Script'))\n",
        "            continue\n",
        "        # normal prompt\n",
        "        result = send(line)\n",
        "        console.print(Panel(result['final'], title='Response', subtitle=f\"len={len(result['final'])}/{result['cap']}\"))\n",
        "        if result['audit']:\n",
        "            md = '\\n'.join([f\"- {a}\" for a in result['audit']])\n",
        "            console.print(Panel(md, title='Audit trail'))\n",
        "        else:\n",
        "            console.print('[dim]No edits needed.[/dim]')\n",
        "\n",
        "repl()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick selfâ€‘test (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to smoke test video scripting\n",
        "# remember('brand','FrostFields')\n",
        "# remember('product','Natural fruit ice cream')\n",
        "# remember('origin','Local farms')\n",
        "# plan = plan_video('short_ad', 20, 'Natural ice cream with coconut & apple')\n",
        "# vid = make_video(plan, style='warm, wholesome', platform='Instagram', debug_first=True)\n",
        "# import json as j; print(j.dumps(vid, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Marketeer_Patched_Video.ipynb"
    },
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
